{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import json\n",
    "import librosa\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_PATH = '/home/long/Source-Code/SpechCommandAppication/archive/augmented_dataset/augmented_dataset/'\n",
    "JSON_PATH='data.json'\n",
    "SAMPLE_RATE = 22050"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(dataset_path, json_path, n_mfcc=13, hop_length=512, n_fft=2048):\n",
    "    # data dictionary\n",
    "    data = {\n",
    "        \"mappings\": [],\n",
    "        \"labels\": [],\n",
    "        \"MFCCs\": [],\n",
    "        \"files\": []\n",
    "    }\n",
    "\n",
    "    # loop through all sub-dirs\n",
    "    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n",
    "        \n",
    "        # Ensure that we're not at the root level\n",
    "        if dirpath is not dataset_path:\n",
    "            category = dirpath.split(\"/\")[-1]  # genre/blues => [\"genre\", \"blues\"] => blues\n",
    "            # update mappings\n",
    "            data[\"mappings\"].append(category)\n",
    "            pbar = tqdm(filenames)\n",
    "            # loop through all the filenames and extract MFCCs\n",
    "            for f in pbar:\n",
    "                pbar.set_description(f'Processing {category}', refresh=True)\n",
    "                # Get file path\n",
    "                file_path = os.path.join(dirpath, f)\n",
    "\n",
    "                # Load audiofile\n",
    "                signal, sr = librosa.load(file_path, mono=True)\n",
    "\n",
    "                # Ensure that all audio files at least 1 sec long\n",
    "                if len(signal) >= sr:\n",
    "\n",
    "                    # ensure signal has 1s long\n",
    "                    signal = signal[:sr]\n",
    "                    # print(signal.shape)\n",
    "                    # Extract MFCCs\n",
    "                    MFCCs = librosa.feature.mfcc(y=signal,\n",
    "                                                 n_mfcc=n_mfcc, \n",
    "                                                 hop_length=hop_length, \n",
    "                                                 n_fft=n_fft)\n",
    "                    \n",
    "                    # store data\n",
    "                    data[\"labels\"].append(i-1)\n",
    "                    data[\"MFCCs\"].append(MFCCs.T.tolist())\n",
    "                    data[\"files\"].append(file_path)\n",
    "                    # print('{}: {}'.format(file_path, i-1))\n",
    "\n",
    "    # Save data to json file\n",
    "    with open(json_path, \"w\") as fp:\n",
    "        json.dump(data, fp, indent=4)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    prepare_dataset(DATASET_PATH, JSON_PATH)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
